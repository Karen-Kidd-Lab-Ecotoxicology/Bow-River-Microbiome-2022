---
title: "Bow River Microbiome Analysis 2022"
author: "Emilie Diesbourg"
date: "19/05/2023"
output: 
  html_document:
    toc: yes
    toc_depth: 2
    df_print: paged
    toc_float: yes
editor_options: 
  chunk_output_type: console
---
#Introduction {.tabset}

This data comes from a study done in 2022 across 5 sites on the Bow River, Calgary AB and 3 microcosm streams from Pine Creek wastewater treatment plant with varying municipal wastewater effluent exposures (mesocosm streams: 0, 5, or 15% effluent flow). The objective of this study is to determine whether there are changes to the microbiome of freshwater macroinvertebrates and riparian Spiders with increased exposure to wastewater. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
```

## Loading Packages
```{r Load packages}
#setwd("Microbiome_ED")
library(phyloseq) #phyloseq will be the main package used for structuring microbiome data and diversity comparisons
#if (!require("BiocManager", quietly = TRUE))
    #install.packages("BiocManager")
#install.packages("viridis")
library(viridis)

#BiocManager::install("apeglm")
library(apeglm)
library(ggplot2) #For creating graphs
library(dplyr) #Helps with data wrangling 
library(cluster) #Used for cluster analyses
library(grid)
library(ape)
library(FSA)
library(multcomp)
library(MASS)
library(glmmTMB)
library(gridExtra)
library(vegan)
library(tidyverse) #data wrangling
library(microbiome) #For microbiome analyses
#if (!require("BiocManager", quietly = TRUE)) #Installing microbiome package
  #install.packages("BiocManager")
#BiocManager::install("microbiome")
library(PERFect) #Permutation filtration for microbiome data. Used when comparing beta diversities across sites/locations. 
#if(!requireNamespace("BiocManager", quietly = TRUE))
  #install.packages("BiocManager")
#BiocManager::install("PERFect")
library(knitr) #For R Markdown knitting
library(kableExtra)
library(speedyseq)
#if (!requireNamespace("remotes", quietly = TRUE))
  #install.packages("remotes")
#remotes::install_github("mikemc/speedyseq")
library(colorspace)
library(RColorBrewer)
library(picante)
library(ggpubr)
library(data.table)
#devtools::install_github("microsud/microbiomeutilities")
library(microbiomeutilities)
library(imsig)
library(phangorn) #For phylogenetic tree
library(metacoder) 
library(tibble)
#if (!require("BiocManager", quietly = TRUE))
    #install.packages("BiocManager")

#BiocManager::install("DESeq2")
library(DESeq2)
library(emmeans)
library(devtools)
#install_github("pmartinezarbizu/pairwiseAdonis/pairwiseAdonis", force=TRUE)
library(pairwiseAdonis)
#library(plyr) apparently if you load this after dpylr it messes up the summarize function?

#if( !require(NbClust) ){install.packages("NbClust"); library(NbClust)}
#if( !require(cobiclust) ){install.packages("cobiclust"); library(cobiclust)}
library(NbClust)
library(cobiclust)
#if (!require("BiocManager", quietly = TRUE))
    #install.packages("BiocManager")

#BiocManager::install("mia")
library(mia)
library(factoextra)
#install.packages(
  #"microViz",
  #repos = c(davidbarnett = "https://david-barnett.r-universe.dev", getOption("repos")))
library(microViz)
library(dendextend) #Formatting dendrograms
#remotes::install_github("vmikk/metagMisc")
library(metagMisc)
```

#Phyloseq object

For a phyloseq object you need 3 pieces of data: 

1. The ASV table with the genetic barcode identifier (the ASV) of each identified bacterial taxa within each insect sample ran (ex. KK100)

2. The taxa table with the genetic barcode of each unique ASV and the respective bacterial classification "Kingdom", "Phylum", "Class", "Order", "Family", "Genus".

3. A metadata file with the sample names (ex. KK100) and any other variables that were measured. Ex. the family of insect or fish organism collected, the site the organism was collected at, the water temperature, the distance to waste water treatment plant, the weight and length of organism, etc.

The phyloseq object will merge all this data together in one object that can be called in by various functions in the phyloseq and microbiome packages. 

```{r Load data and phyloseq object}
#Importing ASV table
ASVseq<-read.csv("C:\\Users\\Emilie\\Documents\\McMaster University 2022-2024\\Bow River Thesis\\BowRiverRProject\\Microbiome_ED\\ASV_data_2022_ED_fulldataset_samplesordered.csv")

#The row names have to be the ASV identifier (genetic barcode) in order for it to be read. The following lines of code are to re-organize the row names
n1 <- ASVseq$X #Currently the ASVs are being called "X" in the first column. We want them to be unnamed in the row names column
ASVseq <- ASVseq[,-1] #This removes the first column of the ASV dataframe
rownames(ASVseq) <- n1 #This moves the ASVs to the rownames column of the dataframe

ASVtable <- as.matrix(ASVseq) #must be a matrix so we convert to a matrix
#View(ASVtable) #The ASVs are now the row names

#Importing taxa table
taxonomy <-read.csv ("C:\\Users\\Emilie\\Documents\\McMaster University 2022-2024\\Bow River Thesis\\BowRiverRProject\\Microbiome_ED\\Taxonomy_ED_2022_fulldataset.csv")

#Using the same steps as above with the ASV table to make the genetic barcode the rowname
n2 <- taxonomy$X
taxonomy <- taxonomy[,-1]
rownames(taxonomy) <- n2

taxa_table<-as.matrix(taxonomy) #Turn into a matrix
#View(taxa_table) #ASVs are now the row names

#Importing metadata file
metadata<-read.csv("C:\\Users\\Emilie\\Documents\\McMaster University 2022-2024\\Bow River Thesis\\BowRiverRProject\\Microbiome_ED\\metadata_ED_withblanks.csv")

metadata$Site<-factor(metadata$Site, levels=c("Cochrane", "Sunalta", "Cushing Bridge", "Graves Bridge", "Policeman Flats", "BRR2", "PCR1", "PCR3")) #Order sites
metadata$Stage<-factor(metadata$Stage, levels=c("Larvae", "Adult", "Spider"), labels=c("Larvae", "Adults", "Spiders"))

#Need to make sample names as row names so we follow the same steps as above. 
n3 <- metadata$Study_ID

# move names to row headings
metadata <- metadata[,-1]
rownames(metadata) <- n3

#View(metadata) #sample names are now row names

#Combining phyloseq object
ASVtable = otu_table(ASVtable, taxa_are_rows = TRUE) #Taxa are rows means that the ASVs of each identified microbe are the row names which we made sure was true
taxa_table = tax_table(taxa_table)

#Make sure the ASV table and taxa table are both matricies before trying to turn into phyloseq object
ps <- phyloseq(ASVtable, sample_data(metadata), taxa_table)
```

#Filtering/pre-processing steps {.tabset}

Experimental samples:

Used package decontam to get rid of contamination from blank samples. Used a prevalence threshold of 0.1 to identify bacteria that were found in high prevalence of blank samples. 

Removing low confidence data: I removed all ASVs identified as Eukaryota and phyla that were identified as <NA>. This removed 39 and 403 taxa respectively. 

Removing low abundance taxa (including singletons and doubletons): I removed taxa whose sums of reads were less than or equal to 5 across all samples.  

Removing low prevalence taxa: I removed taxa that were only found in less than 3 samples (1 or 2). 

Removing low read samples: I removed all samples whose total reads were less than 2000. There was not much difference between a minimum sum of reads as 2000 or 5000 so I decided to use the smaller number of reads (2000) to keep in more samples.

Rarefying: Before statistical analysis (alpha and beta diversity) the reads will be rarefied to the minimum sampling depth to ensure even sampling depth. The minimum even sampling depth is 2048 reads (the lowest read count after filtering). 

In total, 85.3 % of the taxa (ASVs) were filtered out but only 9.5 % of the entire dataset (reads) were filtered out from the original decontaminated dataset. This may have consequences for diversity measures but ensures sequencing errors and contaminants are removed. 


Blank Samples:

Removing low abundance taxa (including singletons and doubletons): I removed taxa whose sums of reads were less than or equal to 10 across all samples. 

Rarefying: Before statistical analysis the reads will be rarefied to the minimum sampling depth to ensure even sampling depth. The minimum even sampling depth is 7946 reads.

In total, 20.7% of the taxa (ASVs) were filtered out but only 0.81% of the entire dataset (reads) were filtered out.

## Decontamination Steps {.tabset}
### Larvae {.tabset}
#### Larvae July
```{r}

#All larvae were collected with tweezers that were rinsed in the DNase/RNase water

#Number of ASVs in the MBDI rinse water from July
KK1952<-subset_samples(ps, Sample_ID=="CUSHBR_MBDI_RINSE_MB_1")
KK1952<-prune_taxa(taxa_sums(KK1952) > 0, KK1952)
ntaxa(KK1952) #85

KK1953<-subset_samples(ps, Sample_ID=="CUSHBR_MBDI_RINSE_MB_2")	
KK1953<-prune_taxa(taxa_sums(KK1953) > 0, KK1953)
ntaxa(KK1953) #78

KK1954<-subset_samples(ps, Sample_ID=="CUSHBR_MBDI_RINSE_MB_3")	
KK1954<-prune_taxa(taxa_sums(KK1954) > 0, KK1954)
ntaxa(KK1954) #25


lar_water_bl<-subset_samples(ps, Blank_collection_method=="Water July")
lar_water_bl_df <- as.data.frame(sample_data(lar_water_bl))
lar_water_bl_df$LibrarySize <- sample_sums(lar_water_bl)
lar_water_bl_df <- lar_water_bl_df[order(lar_water_bl_df$LibrarySize),]
lar_water_bl_df$Index <- seq(nrow(lar_water_bl_df))
ggplot(data=lar_water_bl_df, aes(x=Index, y=LibrarySize, color=Sample_Type)) + geom_point()
#Blank library sizes are very spread out but most of them are lower than experimental sample libraries

sample_data(lar_water_bl)$is.neg <- sample_data(lar_water_bl)$Sample_Type == "Blank"
contamdf.prev.lar.July <- isContaminant(lar_water_bl, method="prevalence", neg="is.neg", threshold=0.1)
hist(contamdf.prev.lar.July$p)
table(contamdf.prev.lar.July$contaminant)
#Threshold of 0.1: FALSE = 31,497, TRUE=59
head(which(contamdf.prev.lar.July$contaminant)) 

#Prune samples to get rid of contaminants and continue with filtering steps
ps.noncontam.lar.July <- prune_taxa(!contamdf.prev.lar.July$contaminant, lar_water_bl)
ps.noncontam.lar.July #31,497 taxa and 122 samples

ps.noncontam.lar.July<-subset_samples(ps.noncontam.lar.July, Sample_Type!="Blank")
nsamples(ps.noncontam.lar.July) #119
```

#### Larvae September
```{r}
#Number of ASVs in the MBDI rinse water from September
KK1955<-subset_samples(ps, Sample_ID=="ACWA_5%_MBDI_RINSE_MB_1")
KK1955<-prune_taxa(taxa_sums(KK1955) > 0, KK1955)
ntaxa(KK1955) #94

KK1956<-subset_samples(ps, Sample_ID=="ACWA_5%_MBDI_RINSE_MB_2")	
KK1956<-prune_taxa(taxa_sums(KK1956) > 0, KK1956)
ntaxa(KK1956) #82

KK1957<-subset_samples(ps, Sample_ID=="ACWA_5%_MBDI_RINSE_MB_3")	
KK1957<-prune_taxa(taxa_sums(KK1957) > 0, KK1957)
ntaxa(KK1957) #150

lar_water_bl_sept<-subset_samples(ps, Blank_collection_method=="Water September")
lar_water_bl_sept_df <- as.data.frame(sample_data(lar_water_bl_sept))
lar_water_bl_sept_df$LibrarySize <- sample_sums(lar_water_bl_sept)
lar_water_bl_sept_df <- lar_water_bl_sept_df[order(lar_water_bl_sept_df$LibrarySize),]
lar_water_bl_sept_df$Index <- seq(nrow(lar_water_bl_sept_df))
ggplot(data=lar_water_bl_sept_df, aes(x=Index, y=LibrarySize, color=Sample_Type)) + geom_point()

sample_data(lar_water_bl_sept)$is.neg <- sample_data(lar_water_bl_sept)$Sample_Type == "Blank"
contamdf.prev.lar.sept <- isContaminant(lar_water_bl_sept, method="prevalence", neg="is.neg", threshold=0.1)
hist(contamdf.prev.lar.sept$p)
table(contamdf.prev.lar.sept$contaminant)
#Threshold of 0.1: FALSE = 31,517, TRUE=39
head(which(contamdf.prev.lar.sept$contaminant)) 

#Prune samples to get rid of contaminants and continue with filtering steps
ps.noncontam.lar.sept <- prune_taxa(!contamdf.prev.lar.sept$contaminant, lar_water_bl_sept)
ps.noncontam.lar.sept #31,534 taxa and 27 samples

ps.noncontam.lar.sept<-subset_samples(ps.noncontam.lar.sept, Sample_Type!="Blank")
nsamples(ps.noncontam.lar.sept) #39
```

### Adults {.tabset}

#### Adults July
```{r}
#Adults collected in July came into contact with the bedsheet
#Sheet blanks from Cochrane and Policeman Flats
KK2072<-subset_samples(ps, Sample_ID=="COCH_MB_SHEET_BL_1")	
KK2072<-prune_taxa(taxa_sums(KK2072) > 0, KK2072)
ntaxa(KK2072) #233

KK2073<-subset_samples(ps, Sample_ID=="COCH_MB_SHEET_BL_2")
KK2073<-prune_taxa(taxa_sums(KK2073) > 0, KK2073)
ntaxa(KK2073) #201

KK2074<-subset_samples(ps, Sample_ID=="POLFLT_MB_SHEET_BL_1")	
KK2074<-prune_taxa(taxa_sums(KK2074) > 0, KK2074)
ntaxa(KK2074) #365

KK2075<-subset_samples(ps, Sample_ID=="POLFLT_MB_SHEET_BL_2")	
KK2075<-prune_taxa(taxa_sums(KK2075) > 0, KK2075)
ntaxa(KK2075) #314

#Subset adults collected from July with the bed sheet and UV light emergence trap
ad_sheet_bl<-subset_samples(ps, Blank_collection_method=="Sheet")
ad_sheet_bl_df <- as.data.frame(sample_data(ad_sheet_bl))
ad_sheet_bl_df$LibrarySize <- sample_sums(ad_sheet_bl)
ad_sheet_bl_df <- ad_sheet_bl_df[order(ad_sheet_bl_df$LibrarySize),]
ad_sheet_bl_df$Index <- seq(nrow(ad_sheet_bl_df))
ggplot(data=ad_sheet_bl_df, aes(x=Index, y=LibrarySize, color=Sample_Type)) + geom_point()

sample_data(ad_sheet_bl)$is.neg <- sample_data(ad_sheet_bl)$Sample_Type == "Blank"
contamdf.prev.ad.sheet <- isContaminant(ad_sheet_bl, method="prevalence", neg="is.neg", threshold=0.1)
hist(contamdf.prev.ad.sheet$p)
table(contamdf.prev.ad.sheet$contaminant)
#Threshold of 0.1: FALSE = 31,231, TRUE=325
head(which(contamdf.prev.ad.sheet$contaminant)) 

#Prune samples to get rid of contaminants and continue with filtering steps
ps.noncontam.ad.sheet <- prune_taxa(!contamdf.prev.ad.sheet$contaminant, ad_sheet_bl)
ps.noncontam.ad.sheet #31,231 taxa and 107 samples

ps.noncontam.ad.sheet<-subset_samples(ps.noncontam.ad.sheet, Sample_Type!="Blank")
nsamples(ps.noncontam.ad.sheet) #103? should be 104?

#Subset POLFLT_1_Ad_Caddis_MB_2 : POLFLT_1_Ad_Caddis_MB_8 from this field decontaminated dataframe because these individuals also got contaminated from the extraction reagents during DNA extraction. No other insect samples were contaminated by this. 

contam.caddis<-subset_samples(ps.noncontam.ad.sheet, Sample_ID %in% c("POLFLT_1_Ad_Caddis_MB_2", "POLFLT_1_Ad_Caddis_MB_3", "POLFLT_1_Ad_Caddis_MB_4", "POLFLT_1_Ad_Caddis_MB_5", "POLFLT_1_Ad_Caddis_MB_6", "POLFLT_1_Ad_Caddis_MB_7", "POLFLT_1_Ad_Caddis_MB_8"))

#Separate extraction reagents so I can combine the POLFLT caddis dataframe together
ext.reag<-subset_samples(ps, Blank_collection_method=="Extraction_neg")
#Merge them together
polflt.caddis<-merge_phyloseq(contam.caddis, ext.reag)

caddis_bl_df <- as.data.frame(sample_data(polflt.caddis))
caddis_bl_df$LibrarySize <- sample_sums(polflt.caddis)
caddis_bl_df <- caddis_bl_df[order(caddis_bl_df$LibrarySize),]
caddis_bl_df$Index <- seq(nrow(caddis_bl_df))
ggplot(data=caddis_bl_df, aes(x=Index, y=LibrarySize, color=Sample_Type)) + geom_point()

sample_data(polflt.caddis)$is.neg <- sample_data(polflt.caddis)$Sample_Type == "Blank"
contamdf.prev.caddis <- isContaminant(polflt.caddis, method="prevalence", neg="is.neg", threshold=0.1)
hist(contamdf.prev.caddis$p)
table(contamdf.prev.caddis$contaminant)
#Threshold of 0.1: FALSE = 31,523, TRUE=33
head(which(contamdf.prev.caddis$contaminant)) 

#Prune samples to get rid of contaminants and continue with filtering steps
ps.noncontam.caddis <- prune_taxa(!contamdf.prev.caddis$contaminant, polflt.caddis)
ps.noncontam.caddis #31,523 taxa and 9 samples

ps.noncontam.caddis<-subset_samples(ps.noncontam.caddis, Sample_Type!="Blank")
nsamples(ps.noncontam.caddis) #7

#Now we have to remove those caddis individuals from the other ps object (ps.noncontam.ad.sheet) so that there aren't duplicates when we merge them all back together. 

ps.noncontam.ad.sheet <- subset_samples(ps.noncontam.ad.sheet, Sample_ID != "POLFLT_1_Ad_Caddis_MB_2" & Sample_ID != "POLFLT_1_Ad_Caddis_MB_3" & Sample_ID !="POLFLT_1_Ad_Caddis_MB_4" & Sample_ID != "POLFLT_1_Ad_Caddis_MB_5" & Sample_ID !="POLFLT_1_Ad_Caddis_MB_6" & Sample_ID !="POLFLT_1_Ad_Caddis_MB_7" & Sample_ID != "POLFLT_1_Ad_Caddis_MB_8")

nsamples(ps.noncontam.ad.sheet) #96

```

##### Adults September


```{r}
#Mesh blanks
#Adults collected in September came into contact with the mesh from floating emergence traps
KK1958<-subset_samples(ps, Sample_ID=="ACWA_5%_MB_MESH_1")	
KK1958<-prune_taxa(taxa_sums(KK1958) > 0, KK1958)
ntaxa(KK1958) #72

KK1959<-subset_samples(ps, Sample_ID=="ACWA_5%_MB_MESH_2")	
KK1959<-prune_taxa(taxa_sums(KK1959) > 0, KK1959)
ntaxa(KK1959) #78

KK1960<-subset_samples(ps, Sample_ID=="ACWA_5%_MB_MESH_3")	
KK1960<-prune_taxa(taxa_sums(KK1960) > 0, KK1960)
ntaxa(KK1960) #133


ad_mesh_bl<-subset_samples(ps, Blank_collection_method=="Mesh")
ad_mesh_bl_df <- as.data.frame(sample_data(ad_mesh_bl))
ad_mesh_bl_df$LibrarySize <- sample_sums(ad_mesh_bl)
ad_mesh_bl_df <- ad_mesh_bl_df[order(ad_mesh_bl_df$LibrarySize),]
ad_mesh_bl_df$Index <- seq(nrow(ad_mesh_bl_df))
ggplot(data=ad_mesh_bl_df, aes(x=Index, y=LibrarySize, color=Sample_Type)) + geom_point()

sample_data(ad_mesh_bl)$is.neg <- sample_data(ad_mesh_bl)$Sample_Type == "Blank"
contamdf.prev.ad.mesh <- isContaminant(ad_mesh_bl, method="prevalence", neg="is.neg", threshold=0.1)
hist(contamdf.prev.ad.mesh$p)
table(contamdf.prev.ad.mesh$contaminant)
#Threshold of 0.1: FALSE = 31,541, TRUE=15
head(which(contamdf.prev.ad.mesh$contaminant)) 

#Prune samples to get rid of contaminants and continue with filtering steps
ps.noncontam.ad.mesh <- prune_taxa(!contamdf.prev.ad.mesh$contaminant, ad_mesh_bl)
ps.noncontam.ad.mesh #31,541 taxa and 19 samples

ps.noncontam.ad.mesh<-subset_samples(ps.noncontam.ad.mesh, Sample_Type!="Blank")
nsamples(ps.noncontam.ad.mesh) #16
```

### Buffer tubes
```{r}
buffer_bl<-subset_samples(ps, Blank_collection_method %in% c("Buffer", "Extraction_neg"))
buffer_bl_df <- as.data.frame(sample_data(buffer_bl))
buffer_bl_df$LibrarySize <- sample_sums(buffer_bl)
buffer_bl_df <- buffer_bl_df[order(buffer_bl_df$LibrarySize),]
buffer_bl_df$Index <- seq(nrow(buffer_bl_df))
ggplot(data=buffer_bl_df, aes(x=Index, y=LibrarySize, color=Blank_collection_method)) + geom_point()

sample_data(buffer_bl)$is.neg <- sample_data(buffer_bl)$Blank_collection_method == "Extraction_neg"
contamdf.prev.buffer <- isContaminant(buffer_bl, method="prevalence", neg="is.neg", threshold=0.1)
hist(contamdf.prev.buffer$p)
table(contamdf.prev.buffer$contaminant)
#Threshold of 0.1: FALSE = 31,543, TRUE=13
head(which(contamdf.prev.buffer$contaminant)) 

#Prune samples to get rid of contaminants and continue with filtering steps
ps.noncontam.buffer <- prune_taxa(!contamdf.prev.buffer$contaminant, buffer_bl)
ps.noncontam.buffer #31,543 taxa and 4 samples

#Only want to keep the buffer blanks not the extraction negs
ps.noncontam.buffer<-subset_samples(ps.noncontam.buffer, Blank_collection_method!="Extraction_neg")
nsamples(ps.noncontam.buffer) #2

#Make a phyloseq for the spiders
spi_ps<-subset_samples(ps, Taxa=="Spider")
```

### Merge all the decontaminated phyloseqs back together
```{r}
nsamples(ps.noncontam.lar.July) #119
nsamples(ps.noncontam.lar.sept) #39
nsamples(ps.noncontam.ad.sheet) #96
nsamples(ps.noncontam.ad.mesh) #16
nsamples(ps.noncontam.caddis) #7
nsamples(ps.noncontam.buffer) #2
nsamples(spi_ps) #80

decontam_ps<-merge_phyloseq(ps.noncontam.lar.July, ps.noncontam.lar.sept, ps.noncontam.ad.sheet, ps.noncontam.ad.mesh, ps.noncontam.buffer, ps.noncontam.caddis, spi_ps)
ntaxa(decontam_ps) #31,556
nsamples(decontam_ps) #359. 357 samples and 2 buffer tubes

#Remove contaminants in all samples due to buffer tubes
sample_contam_df <- as.data.frame(sample_data(decontam_ps))
sample_contam_df$LibrarySize <- sample_sums(decontam_ps)
sample_contam_df <- sample_contam_df[order(sample_contam_df$LibrarySize),]
sample_contam_df$Index <- seq(nrow(sample_contam_df))
ggplot(data=sample_contam_df, aes(x=Index, y=LibrarySize, color=Sample_Type)) + geom_point()

sample_data(decontam_ps)$is.neg <- sample_data(decontam_ps)$Sample_Type == "Blank"
contamdf.prev.sample_contam <- isContaminant(decontam_ps, method="prevalence", neg="is.neg", threshold=0.1)
hist(contamdf.prev.sample_contam$p)
table(contamdf.prev.sample_contam$contaminant)
#Threshold of 0.1: FALSE = 31,209, TRUE=347
head(which(contamdf.prev.sample_contam$contaminant)) 

#Prune samples to get rid of contaminants and continue with filtering steps
ps.noncontam.sample.contam <- prune_taxa(!contamdf.prev.sample_contam$contaminant, decontam_ps)
ps.noncontam.sample.contam #31,209 taxa and 359 samples

#Only want to keep the buffer blanks not the extraction negs
ps.noncontam.sample.contam<-subset_samples(ps.noncontam.sample.contam, Sample_Type!="Blank")
nsamples(ps.noncontam.sample.contam) #357
```

## Experimental Samples {.tabset}
### Removing low confidence taxa
``` {r}
#Subsetting experimental samples only from the decontaminanted phyloseq object
psexp<-subset_samples(ps.noncontam.sample.contam, Sample_Type == "Sample") #Removing ASVs where the abundance is 0 (after removing the blank samples)
psexp<-prune_taxa(taxa_sums(psexp) > 0, psexp)
psexp #30,181 taxa and 357 samples

#Removing Eukaryotes
ps0 <- subset_taxa(psexp, Kingdom != "Eukaryota")
ntaxa(psexp)-ntaxa(ps0) #Got rid of 39 ASVs

#Removing low confidence data (where phylum could not be assigned)
table(tax_table(ps0)[,"Phylum"],exclude=NULL)
ps1<-subset_taxa(ps0, !is.na(Phylum) & !Phylum %in% c("","uncharacterized")) #Removes the phyla characterized as NA
ntaxa(ps0) - ntaxa(ps1) #Got rid of 403 ASVs
ps1 #29.739 taxa, 357 samples
```

### Filtering by abundance and prevalence threshold

```{r}
prevdf=apply(X=otu_table(ps1),MARGIN=ifelse(taxa_are_rows(ps1),yes=1,no=2),FUN = function(x){sum(x > 0)})
# Add taxonomy and total read counts to this data.frame
prevdf= data.frame(Prevalence= prevdf,TotalAbundance=taxa_sums(ps1),tax_table(ps1))

plyr::ddply(prevdf,"Phylum",function(df1){cbind(mean(df1$Prevalence),sum(df1$TotalAbundance))}) 
#Shows mean and total prevalence of taxa within each phylum. The ones that are only prevalent once in each phylum might be worth removing. This means they only showed up in one sample across all samples but might have a high abundance (total number of reads).  

#There are a couple of phyla with only a prevalence sum of one or two so these might be worth removing. 

ps1.dt.taxa = data.table(tax_table(ps1), OTUabundance = taxa_sums(ps1), OTU = taxa_names(ps1)) 
ps1.cumsum = ps1.dt.taxa[, .N, by = OTUabundance]
setkey(ps1.cumsum, OTUabundance)
ps1.cumsum[, CumSum := cumsum(N)]
# Define the plot
ps1.cumsum.plot = ggplot(ps1.cumsum, aes(OTUabundance, CumSum)) + 
  geom_point() +
  xlab("Filtering Threshold, Minimum Total Counts") +
  ylab("OTUs Filtered") +
  ggtitle("OTUs that would be filtered vs. the minimum count threshold") + theme_bw()

print(ps1.cumsum.plot) #Difficult to see the smaller values so we need to zoom in

ps1.cumsum.plot.zoom <- ps1.cumsum.plot + xlim(0, 50) + theme_bw() 

print(ps1.cumsum.plot.zoom) 
#Could maybe remove taxa with an abundance of less than 5-6 across all samples however if I go higher than that it filters out a ton of taxa (about 1/3 of all of them)

#I will filter out taxa that are only prevalent in 1% of all samples (has to be in at least 4/357 samples)
ps2<-phyloseq_filter_prevalence(ps1, prev.trh = 0.01, abund.trh = 6, threshold_condition = "AND")
ps2 #4434 taxa, 357 samples. Got rid of 25,227 ASVs
any(taxa_sums(ps2) <6) #FALSE. Means it did a good job of getting rid of them. 
```

### Filtering by a minimum total sample count (at least 2000 reads/sample)

```{r}
#Creating a rarefaction curve
tab <- otu_table(ps2)
class(tab) <- "matrix" # as.matrix() will do nothing
## you get a warning here, but this is what we need to have
tab <- t(tab) # transpose observations to rows
rare <- rarecurve(tab, step=5000, lwd=2, ylab="OTU",  label=F) 
#The rarefaction curves are very spread out. This means that there are different sequencing depths and standardizing the data will be required for analysis. 

sort(sample_sums(ps2)) #minimum is 24, maximum is 222,584
mean(sample_sums(ps2)) #31,088

#Final dataset
sample_ps <- subset_samples(ps2, sample_sums(ps2) > 2000) 
sort(sample_sums(sample_ps)) #Minimum sampling depth is now 2048 reads. Got rid of 38 samples (319 samples left).
sample_ps #4434 taxa, 319 samples. 

#Excel file with samples that were pruned out
pruned_df<-psmelt(subset_samples(ps2, sample_sums(ps2) < 2000))
#write.csv(pruned_df, file="Filtering phyloseq/Samples pruned from 2000 reads per sample.csv")
```

### Amount of data that was filtered out from the original phyloseq object

```{r}
ntaxa(psexp)-ntaxa(sample_ps) #filtered 25,747 total taxa (ASVs)
(1-ntaxa(sample_ps)/ntaxa(psexp))*100 #85.3% of the taxa were removed from the original decontaminated dataset. 

reads_per_OTU <- taxa_sums(psexp) #Original ps with no filtering done.
print(sum(reads_per_OTU)) #Total number of reads is 12222269.

reads_per_OTU_filtered <- taxa_sums(sample_ps) #Original ps with no filtering done.
print(sum(reads_per_OTU_filtered)) #Total number of reads is now 11065513.

(1-11065513/12222269)*100 #9.5%. Filtered out a smaller percentage of the total data (reads). 

#From this we can conclude that a small part of the data (~10%) can have a significant effect on downstream analyses (~85% of taxa removed), if  methods that use ASVs instead of the information that is contained in the sequences is implemented, such as Unifrac and phylogenetic diversity.


#Creating a distribution of reads per sample versus the sample counts. 
ps1_df= data.table(as(sample_data(sample_ps), "data.frame"), Reads_per_sample = sample_sums(sample_ps), keep.rownames = TRUE)
ps1_df_plot = ggplot(ps1_df, aes(Reads_per_sample)) + geom_histogram() + ggtitle("Distribution of reads per sample") + ylab("Sample counts") 

print(ps1_df_plot) #Looks right skewed. A couple of very large reads per sample. Probably the perlidae individuals because they are so big compared to some of the other samples like chironomids. Most are around 20,000 - 40,000 reads per sample though.

#Now we need to observe the counts of abundance of unique sequences across samples
ps1.dt.taxa = data.table(tax_table(sample_ps), OTUabundance = taxa_sums(sample_ps), OTU = taxa_names(sample_ps)) 
#makes a data table of the sum of abundance of each taxa vs the total number of taxa (ASVs)
ps1.dt.tax.plot<- ggplot(ps1.dt.taxa, aes(OTUabundance)) + geom_histogram() + ggtitle("Histogram of OTU (unique sequence) counts") + theme_bw() #Plots the number of times an ASV is repeated from the reads (abundance) on the x axis and the number of taxa on the y axis
print(ps1.dt.tax.plot)
#You can"t see much on the plots panel in R

#write.table(ps1.dt.taxa, "Filtering phyloseq/ps1_dt_tax_plot.txt", sep = "\t") #makes a table that can open in excel

#ggsave("Filtering phyloseq/Histogram of OTU counts.pdf", height = 6, width = 7) #pdf of the plot

#This plot shows that there is a very small proportion of ASVs with a really high abundance and most have relatively low abundance. Highly right skewed. We want to see how many have very low abundance because this may indicate that further processing/filtering should be done. 

#Zoom in on the lower abundance counts to get a better idea of its distribution
plot.zoom1 <- ggplot(ps1.dt.taxa, aes(OTUabundance)) + geom_histogram(breaks=seq(0, 100, by =10)) + ggtitle("Histogram of Total Counts") + theme_bw()
print(plot.zoom1)
#ggsave("Filtering phyloseq/Histogram of OTU counts 1 to 100.pdf", height = 6, width = 7)
#A very high proportion of ASVs have an abundance of less than 10. This may indicate that they should be filtered out. 

plot.zoom2 <- ggplot(ps1.dt.taxa, aes(OTUabundance)) + geom_histogram(breaks=seq(0, 10, by =2)) + ggtitle("Histogram of Total Counts") + theme_bw()
print(plot.zoom2)
#ggsave("Filtering phyloseq/Histogram of OTU counts 1 to 10.pdf", height = 6, width = 7)
```

## Blank Samples
```{r}
#Subsetting experimental samples only from the original phyloseq object
psbl<-subset_samples(ps, Sample_Type != "Sample") #Removing ASVs where the abundance is 0 (after removing the blank samples)
psbl<-prune_taxa(taxa_sums(psbl) > 0, psbl)
psbl #1809 taxa and 23 samples

#Removing low confidence data (where phylum could not be assigned)
table(tax_table(psbl)[,"Phylum"],exclude=NULL) #No taxa assigned as a phyla of NA
#Seems like some of these phyla with a prevalence of 1 also only showed up once in the experimental samples. These ones may need to be filtered out of the experimental samples if it originated just from the sheet/mesh/water blanks.

#Getting rid of singletons and doubletons
any(taxa_sums(psbl)>=2) #TRUE. Means there are ASVs with a sum of sequences less than 2 across all samples. 
psbl0 <- prune_taxa(taxa_sums(psbl) > 2, psbl) #Getting rid of singletons and doubletons. (Taxa that only showed up in one or two sequences across all samples)
any(taxa_sums(psbl0) <2) #FALSE. Means they were removed. 
ntaxa(psbl)- ntaxa(psbl0) #Got rid of 44 ASVs. 

#How many bacterial taxa do we have/did we remove
ntaxa(psbl) #1809 before any filtering was done.
ntaxa(psbl0) #1765 after sum of reads less than 2 were removed (44 removed).


# Compute prevalence of each feature, store as data.frame
prevdf=apply(X=otu_table(psbl0),MARGIN=ifelse(taxa_are_rows(psbl0),yes=1,no=2),FUN = function(x){sum(x > 0)})
# Add taxonomy and total read counts to this data.frame
prevdf= data.frame(Prevalence= prevdf,TotalAbundance=taxa_sums(psbl0),tax_table(psbl0))

plyr::ddply(prevdf,"Phylum",function(df1){cbind(mean(df1$Prevalence),sum(df1$Prevalence))}) 
#The low prevalence phyla showed up in the experimental samples as well. Could be due to sequencing errors, contamination during extraction, or real observations in the blanks. Not sure. 

plyr::ddply(prevdf, "Phylum", function(df1){
  data.frame(mean_prevalence=mean(df1$Prevalence),total_abundance=sum(df1$TotalAbundance,na.rm = T),stringsAsFactors = F)
  })

#Creating a rarefaction curve
tab <- otu_table(psbl0)
class(tab) <- "matrix" # as.matrix() will do nothing
## you get a warning here, but this is what we need to have
tab <- t(tab) # transpose observations to rows
library(vegan)
rare <- rarecurve(tab, step=5000, lwd=2, ylab="OTU",  label=F) 

sort(sample_sums(psbl0)) #minimum is 16, maximum is 63,491
mean(sample_sums(psbl0)) #mean is 21,888

#Remove samples with a sequencing depth less than 7000 (most of the laboratory blanks)
psbl1<-subset_samples(psbl0, sample_sums(psbl0) > 7000) 
sort(sample_sums(psbl1)) #lowest is 7949 reads.

#How much data did we filter out from the original phyloseq object?

ntaxa(psbl)-ntaxa(psbl1) #filtered 44 total taxa (ASVs)
(1-ntaxa(psbl1)/ntaxa(psbl))*100 #2.43% of the taxa were removed from the original dataset. 

reads_per_OTU <- taxa_sums(psbl) #Original ps with no filtering done.
print(sum(reads_per_OTU)) #Total number of reads is 503,506.

reads_per_OTU_filtered <- taxa_sums(psbl1) #Original ps with no filtering done.
print(sum(reads_per_OTU_filtered)) #Total number of reads is now 501,503.

(1-501503/503506)*100 #0.40%. Only filtered out a very small percentage of the total data (reads). 


#Creating a distribution of reads per sample versus the sample counts. 
ps1_df= data.table(as(sample_data(psbl1), "data.frame"), Reads_per_sample = sample_sums(psbl1), keep.rownames = TRUE)
ps1_df_plot = ggplot(ps1_df, aes(Reads_per_sample)) + geom_histogram() + ggtitle("Distribution of reads per sample") + ylab("Sample counts") 

print(ps1_df_plot) #All over the place. Not really any sequencing depth that is consistent across all samples

#Now we need to observe the counts of abundance of unique sequences across samples
ps1.dt.taxa = data.table(tax_table(psbl1), OTUabundance = taxa_sums(psbl1), OTU = taxa_names(psbl1)) 
#makes a data table of the sum of abundance of each taxa vs the total number of taxa (ASVs)
ps1.dt.tax.plot<- ggplot(ps1.dt.taxa, aes(OTUabundance)) + geom_histogram() + ggtitle("Histogram of OTU (unique sequence) counts") + theme_bw() #Plots the number of times an ASV is repeated from the reads (abundance) on the x axis and the number of taxa on the y axis
print(ps1.dt.tax.plot)
#You can"t see much on the plots panel in R but not a very high abundance in most samples. One sample has a really high abundance.

#This plot shows that there is a very small proportion of ASVs with a really high abundance and most have relatively low abundance. Highly right skewed. We want to see how many have very low abundance because this may indicate that further processing/filtering should be done. 

#Zoom in on the lower abundance counts to get a better idea of its distribution
plot.zoom1 <- ggplot(ps1.dt.taxa, aes(OTUabundance)) + geom_histogram(breaks=seq(0, 100, by =10)) + ggtitle("Histogram of Total Counts") + theme_bw()
print(plot.zoom1)

#A small proportion of ASVs have an abundance of less than 10. These may be able to be filtered out. 

plot.zoom2 <- ggplot(ps1.dt.taxa, aes(OTUabundance)) + geom_histogram(breaks=seq(0, 10, by =2)) + ggtitle("Histogram of Total Counts") + theme_bw()
print(plot.zoom2)

#Only about 200 taxa have a prevalence below 10. 

#Finding total number of reads vs # of reads with low abundance counts
reads_per_OTU <- taxa_sums(psbl1)
print(sum(reads_per_OTU)) #Total number of reads is 501,503.

#How many taxa (ASVs) contain less than 10 reads (an abundance of 10 or less)?
print(length(reads_per_OTU[reads_per_OTU <=10])) #330. 

#How many reads do these 330 ASVs contain in total?
print(sum(reads_per_OTU[reads_per_OTU <=10])) #2066

#What percentage of the total reads is that?
print((sum(reads_per_OTU[reads_per_OTU <=10])/sum(reads_per_OTU))*100) #0.41 %. A very small proportion of the entire dataset. 

#How many ASVs out of the total number of ASVs contains less than or equal to 10 reads?
ntaxa(psbl1) #1765

print((330/1765)*100) #18.7% 


#Plotting the number of ASVs that would be filtered out given a minimum read threshold (min abundance of ASVs)
ps1.dt.taxa = data.table(tax_table(psbl1), OTUabundance = taxa_sums(psbl1), OTU = taxa_names(psbl1)) 
ps1.cumsum = ps1.dt.taxa[, .N, by = OTUabundance]
setkey(ps1.cumsum, OTUabundance)
ps1.cumsum[, CumSum := cumsum(N)]
# Define the plot
ps1.cumsum.plot = ggplot(ps1.cumsum, aes(OTUabundance, CumSum)) + 
  geom_point() +
  xlab("Filtering Threshold, Minimum Total Counts") +
  ylab("OTUs Filtered") +
  ggtitle("OTUs that would be filtered vs. the minimum count threshold") + theme_bw()

print(ps1.cumsum.plot) #Difficult to see the smaller values so we need to zoom in

ps1.cumsum.plot.zoom <- ps1.cumsum.plot + xlim(0, 50) + theme_bw() 

print(ps1.cumsum.plot.zoom) 
#Could maybe remove taxa with an abundance of less than 10 across all samples

#Can also check the coefficient of variation for spurious observations. *How do you tell which ones are spurious observations?*
ps1.rel <- microbiome::transform(psbl1, "compositional") # transform to relative abundance
p <- plot_taxa_cv(ps1.rel, plot.type="scatter")
print(p) #The low abundance ASVs have a very high coefficient of variation which may affect the differential abundance testing. 

#I will filter out taxa with an abundance of 10 or less. 


blank_ps <- prune_taxa(taxa_sums(psbl1) > 10, psbl1)
blank_ps<- prune_taxa(taxa_sums(blank_ps) > 0, blank_ps)
blank_ps #1435 taxa instead of 1809. Removed 374 ASVs in total.
any(taxa_sums(blank_ps)<=10) #FALSE. Removed them adequately. 

sort(sample_sums(blank_ps)) #Lowest was 7946, highest was 63246. Seems pretty high for a blank sample but not too variable.
mean(sample_sums(blank_ps)) #mean is 29378

#How much data did we filter out from the original phyloseq object?

ntaxa(psbl)-ntaxa(blank_ps) #filtered 374 total taxa (ASVs)
(1-ntaxa(blank_ps)/ntaxa(psbl))*100 #20.7% of the taxa were removed from the original dataset. 

reads_per_OTU <- taxa_sums(psbl) #Original ps with no filtering done.
print(sum(reads_per_OTU)) #Total number of reads is 503506

reads_per_OTU_filtered <- taxa_sums(blank_ps) #Original ps with no filtering done.
print(sum(reads_per_OTU_filtered)) #Total number of reads is now 499437.

(1-499437/503506)*100 #0.81%. Only filtered out a small percentage of the total data (reads). 


```

## Finding a good prevalence threshold
```{r}

##Prevalence threshold pruning ##
# Define prevalence of each taxa (in how many samples did each taxa appear at least once)
prev0 = apply(X = otu_table(sample_ps),
                MARGIN = ifelse(taxa_are_rows(sample_ps), yes = 1, no = 2),
                FUN = function(x){sum(x > 0)})
prevdf = data.frame(Prevalence = prev0,
                      TotalAbundance = taxa_sums(sample_ps),
                      tax_table(sample_ps))
keepPhyla = table(prevdf$Phylum)[(table(prevdf$Phylum) > 2)] #Keeping phyla with a prevalence greater than 2
prevdf1 = subset(prevdf, Phylum %in% names(keepPhyla))
# Define prevalence threshold as 5% of total samples
prevalenceThreshold = 0.02 * nsamples(sample_ps)
prevalenceThreshold #We are keeping phyla that occur at least 6.88 samples (2% of samples) with a prevalence of 2 or greater 

psprune = prune_taxa((prev0 > prevalenceThreshold), sample_ps)
psprune #2849 taxa instead of 27,069. Cut out a very large portion of the data. Too high of a threshold.  

reads_pruned <- taxa_sums(psprune)
print(sum(reads_pruned)) #11,306,751 total reads left after pruning
(1-(sum(reads_pruned))/(sum(reads_per_OTU)))*100 #14.55% of the total read data was removed by pruning. A decently large portion of the data was cut out from additional pruning

ggplot(prevdf1, aes(TotalAbundance, Prevalence, color = Phylum)) +
  geom_hline(yintercept = prevalenceThreshold, alpha = 0.5, linetype = 2) +
  geom_point(size = 2, alpha = 0.7) +
  scale_y_log10() + scale_x_log10() +
  xlab("Total Abundance") +
  facet_wrap(~Phylum)
#Prevalence threshold looks too high, cutting out a lot of the variation in microbial communities. I will try a lower threshold value. 


#Lowering the prevalence threshold to 0.2%

# Define prevalence of each taxa
# (in how many samples did each taxa appear at least once)
prev1 = apply(X = otu_table(sample_ps),
                MARGIN = ifelse(taxa_are_rows(sample_ps), yes = 1, no = 2),
                FUN = function(x){sum(x > 0)})
prevdf2 = data.frame(Prevalence = prev1,
                      TotalAbundance = taxa_sums(sample_ps),
                      tax_table(sample_ps))
keepPhyla1 = table(prevdf2$Phylum)[(table(prevdf2$Phylum) > 2)]
prevdf3 = subset(prevdf2, Phylum %in% names(keepPhyla))
# Define prevalence threshold as 5% of total samples
prevalenceThreshold1 = 0.01 * nsamples(sample_ps)
prevalenceThreshold1 #3.44. 

psprune1 = prune_taxa((prev1 > prevalenceThreshold1), sample_ps)
psprune1 #4614 taxa instead of 27,069. Got rid of 22455 ASVs. Still a very large percentage of taxa removed.

reads_pruned1 <- taxa_sums(psprune1)
print(sum(reads_pruned1)) #13 231 428 total reads left after pruning
(1-(sum(reads_pruned1))/(sum(reads_per_OTU)))*100 #0% of data was removed. Why did it remove 297 ASVs but none of the reads??

ggplot(prevdf2, aes(TotalAbundance, Prevalence, color = Phylum)) +
  geom_hline(yintercept = prevalenceThreshold1, alpha = 0.5, linetype = 2) +
  geom_point(size = 2, alpha = 0.7) +
  scale_y_log10() + scale_x_log10() +
  xlab("Total Abundance") +
  facet_wrap(~Phylum)
#This threshold of filtering looks a lot better and I can be more confidence that we are not removing true taxa from samples. Looks like the ones that are removed are just artifacts of sampling or sequencing errors. 
```

## Simplified filtering steps for reloading data quickly
```{r}
#Experimental Samples

#Decontamination
sample_data(ps)$is.neg <- sample_data(ps)$Sample_Type == "Blank"
contamdf.prev01 <- isContaminant(ps, method="prevalence", neg="is.neg", threshold=0.1)

#Prune samples to get rid of contaminants and continue with filtering steps
ps.noncontam <- prune_taxa(!contamdf.prev01$contaminant, ps)
ps.noncontam #30,782 taxa and 380 samples

psexp<-subset_samples(ps.noncontam, Sample_Type == "Sample") #Removing ASVs where the abundance is 0 (after removing the blank samples)
psexp<-prune_taxa(taxa_sums(psexp) > 0, psexp)
psexp #30,181 taxa and 357 samples

#Removing Eukaryotes
ps0 <- subset_taxa(psexp, Kingdom != "Eukaryota")
ntaxa(psexp)-ntaxa(ps0) #Got rid of 39 ASVs

#Removing low confidence data (where phylum could not be assigned)
ps1<-subset_taxa(ps0, !is.na(Phylum) & !Phylum %in% c("","uncharacterized")) #Removes the phyla characterized as NA
ntaxa(ps0) - ntaxa(ps1) #Got rid of 403 ASVs

ps2<-phyloseq_filter_prevalence(ps1, prev.trh = 0.01, abund.trh = 6, threshold_condition = "AND")
ps2 #4434 taxa, 357 samples. 
any(taxa_sums(ps2) <6) #FALSE. Means it did a good job of getting rid of them. 

sample_ps <- subset_samples(ps2, sample_sums(ps2) > 2000) 
sort(sample_sums(sample_ps)) #Minimum sampling depth is now 2048 reads. Got rid of 38 samples (319 samples left).
sample_ps #4434 taxa, 319 samples. 
psexp #Got rid of 85.3 % of ASVs

reads_per_OTU_ps <- taxa_sums(sample_ps) 
print(sum(reads_per_OTU_ps)) #11,065,513 reads. 
#Removed ~10% of the experimental samples after decontamination. 
reads_per_OTU_expps <- taxa_sums(psexp) 
print(sum(reads_per_OTU_expps)) #12,222,269
#removed 9.5% of reads


#Blank samples

psbl<-subset_samples(ps, Sample_Type != "Sample") #Removing ASVs where the abundance is 0 (after removing the blank samples)
psbl<-prune_taxa(taxa_sums(psbl) > 0, psbl)
psbl

any(taxa_sums(psbl)>=2) #TRUE. Means there are ASVs with a sum of sequences less than 2 across all samples. 
psbl0 <- prune_taxa(taxa_sums(psbl) > 2, psbl) #Getting rid of singletons and doubletons. (Taxa that only showed up in one or two sequences across all samples)
any(taxa_sums(psbl0) <2) #FALSE. Means they were removed. 
ntaxa(psbl)- ntaxa(psbl0) #Got rid of 32 ASVs. 

#How many bacterial taxa do we have/did we remove
ntaxa(psbl) #1809 before any filtering was done.
ntaxa(psbl0) #1765 after sum of reads less than 2 were removed (32 removed).

psbl1<-subset_samples(psbl0, sample_sums(psbl0) > 7000) 
sort(sample_sums(psbl1)) #lowest is 7949 reads.

blank_ps <- prune_taxa(taxa_sums(psbl1) > 10, psbl1)
blank_ps<- prune_taxa(taxa_sums(blank_ps) > 0, blank_ps)
blank_ps #1435 taxa instead of 1809. 
```

